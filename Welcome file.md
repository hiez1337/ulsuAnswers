

## Ответы на вопросы по курсу «Математическая статистика»

## 1. Генеральная совокупность, выборка, выборочный метод. Вариационный ряд. Порядковые статистики.**  _(Лекция 1, п. 1.2)_

* **Генеральная совокупность** - это множество всех объектов, относительно которых делаются выводы в статистическом исследовании.
* **Выборка** - это подмножество объектов, отобранных из генеральной совокупности для анализа. 
* **Выборочный метод** - это способ получения информации о генеральной совокупности на основе анализа выборки. 
* **Вариационный ряд** - это упорядоченная по возрастанию выборка: $X_{(1)} \le X_{(2)} \le ... \le X_{(n)}$.
* **Порядковые статистики** - это элементы вариационного ряда, т.е. $X_{(k)}$, где $k=1,...,n$, называется k-й порядковой статистикой.


## 2. Эмпирическая функция распределения, гистограмма и их свойства.** _(Лекция 1, п. 1.3, 1.5)_

* **Эмпирическая функция распределения (ЭФР)**, построенная по выборке $X_1,...,X_n$ объема n, определяется как: 
$$F_n^*(y) = \frac{\text{количество } X_i \in (-\infty, y)}{n} = \frac{1}{n} \sum_{i=1}^{n} I(X_i < y)$$, 
где $I(X_i < y)$ - индикаторная функция события ${X_i < y}$.
    * **Свойства ЭФР:**
        * **Несмещенность:** $EF_n^*(y) = F(y)$.
        * **Состоятельность:** $F_n^*(y) \xrightarrow{p} F(y)$ при $n \to \infty$ (Теорема 1).
        * **Равномерная сходимость:** $\sup_{y \in R} |F_n^*(y) - F(y)| \xrightarrow{p} 0$ при $n \to \infty$ (Теорема Гливенко-Кантелли).
        * **Асимптотическая нормальность:** $\sqrt{n}(F_n^*(y) - F(y)) \Rightarrow N_{0, F(y)(1-F(y))}$ (Свойство 1).
        * **Биномиальное распределение:** $n \cdot F_n^*(y)$ имеет биномиальное распределение $B_{n, F(y)}$ (Свойство 1). 

* **Гистограмма** - это графическое представление распределения выборки, построенное по группированным данным. Область значений выборки делится на интервалы, а над каждым интервалом строится прямоугольник, площадь которого пропорциональна числу элементов выборки, попавших в этот интервал.
    * **Свойства гистограммы:**
        * При $n \to \infty$ высота столбца гистограммы сближается со значением плотности распределения в точке этого интервала (Теорема 4).
        * Площадь столбца гистограммы сближается с площадью под графиком плотности над этим интервалом (Теорема 4).

## 3. Эмпирические моменты и их свойства.** _(Лекция 1, п. 1.4, 1.5)_

* **Эмпирические (выборочные) моменты** - это аналоги теоретических моментов, вычисленные по выборке:
    * **Выборочное среднее:** $\overline{X} = \frac{1}{n} \sum_{i=1}^{n} X_i$.
        * **Несмещенность:** $E \overline{X} = E X_1 = a$.
        * **Состоятельность:** $\overline{X} \xrightarrow{p} EX_1 = a$ (Лемма 1).
    * **Выборочная дисперсия:** $\sigma_*^2 = \frac{1}{n} \sum_{i=1}^{n} (X_i - \overline{X})^2$.
        * **Смещенность:** $E\sigma_*^2 = \frac{n-1}{n} DX_1 \neq DX_1 = \sigma^2$ (Лемма 2).
        * **Состоятельность:** $\sigma_*^2 \xrightarrow{p} DX_1 = \sigma^2$ (Лемма 2).
    * **Несмещенная выборочная дисперсия:** $S_0^2 = \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \overline{X})^2$.
        * **Несмещенность:** $ES_0^2 = DX_1 = \sigma^2$ (Лемма 2).
        * **Состоятельность:** $S_0^2 \xrightarrow{p} DX_1 = \sigma^2$ (Лемма 2).
    * **Выборочный k-й момент:** $\overline{X^k} = \frac{1}{n} \sum_{i=1}^{n} X_i^k$.
        * **Несмещенность:** $E \overline{X^k} = E X_1^k = m_k$ (Лемма 3).
        * **Состоятельность:** $\overline{X^k} \xrightarrow{p} EX_1^k = m_k$ при $n \to \infty$ (Лемма 3).

## 4. Параметрические семейства распределений. Точечные оценки. Несмещенные и состоятельные оценки.** _(Лекция 2, п. 2.1, 2.2)_

* **Параметрические семейства распределений** - это классы распределений, которые полностью определяются значением одного или нескольких параметров. 
* **Точечная оценка** - это число, которое используется для приближения неизвестного параметра распределения.
* **Несмещенная оценка** - это оценка, математическое ожидание которой равно истинному значению параметра.
* **Состоятельная оценка** - это оценка, которая сходится по вероятности к истинному значению параметра при увеличении объема выборки.

## 5. Метод моментов.** _(Лекция 2, п. 2.3, 2.4)_

* **Метод моментов** - это способ получения оценок параметров распределения, основанный на сравнении выборочных моментов с теоретическими. Если $E_\theta X_1^k = h(\theta)$, где $h$ обратима, то оценка метода моментов для $\theta$ находится из уравнения: $\overline{X^k} = h(\theta^*)$.
* **Состоятельность:** Если функция $h^{-1}$ непрерывна, то оценка метода моментов $\theta^* = h^{-1}(\overline{X^k})$ состоятельна (Теорема 5).

## 6. Метод максимального правдоподобия.** _(Лекция 2, п. 2.5)_

* **Метод максимального правдоподобия** - это способ получения оценок параметров распределения, основанный на максимизации функции правдоподобия. 
* **Функция правдоподобия:** $\Psi(\overline{X}, \theta) = \prod_{i=1}^{n} f_\theta(X_i)$, где $f_\theta(y)$ - плотность распределения $F_\theta$.
* **Логарифмическая функция правдоподобия:** $L(\overline{X}, \theta) = \ln \Psi(\overline{X}, \theta) = \sum_{i=1}^{n} \ln f_\theta(X_i)$.
* **Оценка максимального правдоподобия (ОМП)**: $\hat{\theta}$ - значение $\theta$, при котором функция $\Psi(\overline{X}, \theta)$ или $L(\overline{X}, \theta)$ достигает максимума. 

## 7. Способы сравнения оценок. Среднеквадратический подход. Эффективные оценки.** _(Лекция 3, п. 3.1, 3.2)_

* **Среднеквадратический подход:** Оценка $\theta_1^$ лучше оценки $\theta_2^$ в смысле среднеквадратического подхода, если для любого $\theta \in \Theta$: $E_\theta(\theta_1^* - \theta)^2 \le E_\theta(\theta_2^* - \theta)^2$ и хотя бы при одном $\theta$ неравенство строгое.
* **Эффективная оценка:** Оценка $\theta^*$ называется эффективной в классе оценок с одинаковым смещением, если она лучше (не хуже) всех других оценок этого класса в смысле среднеквадратического подхода.
* **Просто эффективная оценка:** Эффективная оценка в классе несмещенных оценок называется просто эффективной. 

**8. Регулярность семейства распределений. Информация по Фишеру. Неравенство Рао-Крамера.** _(Лекция 4, п. 4.1, 4.2, 4.3)_

* **Условие регулярности (R):** Для почти всех $y \in R$ функция $\sqrt{f_\theta(y)}$ непрерывно дифференцируема по $\theta$ во всех точках $\theta \in \Theta$.
* **Информация по Фишеру:** $I(\theta) = E_\theta \left( \frac{\partial}{\partial \theta} \ln f_\theta (X_1) \right)^2$.
* **Неравенство Рао-Крамера:**  Пусть семейство распределений $F_\theta$ удовлетворяет условиям (R) и информация по Фишеру $I(\theta)$ существует, положительна и непрерывна по $\theta$.  
    * Для несмещенной оценки $\theta^*$: $D_\theta \theta^* = E_\theta (\theta^* - \theta)^2 \ge \frac{1}{n I(\theta)}$ (Теорема 10).
    * Для оценки $\theta^*$ со смещением $b(\theta)$: $E_\theta (\theta^* - \theta)^2 \ge \frac{(1 + b'(\theta))^2}{n I(\theta)} + b^2(\theta)$ (Теорема 11).


## 9. Интервальные оценки. Доверительный интервал. _(Лекция 5, п. 5.1)_

В математической статистике, помимо точечных оценок, которые представляют собой одно число, используются также **интервальные оценки**.  Они дают более полное представление о возможном значении оцениваемого параметра, указывая интервал, в котором он может находиться с определенной вероятностью.

**Доверительный интервал (ДИ)** -  это интервал, построенный по выборке, который с заданной вероятностью (называемой **уровнем доверия**) покрывает истинное значение оцениваемого параметра. 

**Формальное определение:** 
Пусть  $0 < \epsilon < 1$. Интервал $(\theta^-, \theta^+) = (\theta^-(\overline{X}, \epsilon), \theta^+(\overline{X}, \epsilon))$ называется  **доверительным интервалом** для параметра $\theta$  **уровня доверия** $1 - \epsilon$, если для любого $\theta \in \Theta$ выполняется:

$$P_\theta (\theta^- < \theta < \theta^+) = P_\theta ((\theta^-, \theta^+) \ni \theta) \ge 1 - \epsilon$$

**Ключевые моменты:**

* **Случайность границ:**  Важно понимать, что границы доверительного интервала  $\theta^-$  и  $\theta^+$  являются  *случайными величинами*, зависящими от выборки.
* **Интерпретация:**  Правильная интерпретация доверительного интервала  *не*  в том, что истинное значение параметра с вероятностью  $1 - \epsilon$  лежит внутри интервала.  Правильно говорить, что  *интервал покрывает истинное значение параметра*  с вероятностью  $1 - \epsilon$.
* **Уровень доверия:** Уровень доверия  $1 - \epsilon$  выбирается исследователем и отражает степень уверенности в том, что построенный интервал  действительно покрывает истинное значение параметра.  Чем выше уровень доверия, тем шире будет доверительный интервал.

**Асимптотический доверительный интервал:** 

В некоторых случаях построение точного доверительного интервала затруднительно. Тогда используется понятие **асимптотического доверительного интервала**, уровень доверия которого стремится к заданному значению при увеличении объема выборки.

**Формальное определение:** 
Пусть  $0 < \epsilon < 1$. Интервал $(\theta^-, \theta^+) = (\theta^-(\overline{X}, \epsilon), \theta^+(\overline{X}, \epsilon))$ называется  **асимптотическим доверительным интервалом** для параметра $\theta$ (асимптотического) **уровня доверия** $1 - \epsilon$, если для любого $\theta \in \Theta$ выполняется:

$$\lim_{n \to \infty} P_\theta (\theta^- < \theta < \theta^+) = \lim_{n \to \infty} P_\theta ((\theta^-, \theta^+) \ni \theta) \ge 1 - \epsilon$$

**Построение доверительных интервалов:**

Существуют различные методы построения доверительных интервалов, основанные на использовании распределений, связанных с нормальным (например, распределения Стьюдента, хи-квадрат),  а также на асимптотической нормальности оценок.  Подробные примеры построения ДИ приведены в Лекциях 5 и 6. 


## 10. Распределения вероятностей, связанные с нормальным: Пирсона, Стьюдента. Лемма Фишера.** _(Лекция 6, п. 6.1, 6.2, 6.3, 6.4, 6.5)_

* **Распределение $\chi^2$ (Пирсона) с k степенями свободы ($H_k$):** 
    * Определение: распределение суммы квадратов $k$ независимых стандартных нормальных случайных величин: $\chi_k^2 = \xi_1^2 + ... + \xi_k^2$, где $\xi_i \sim N(0,1)$.
    * Свойства:
        * $E\chi_k^2 = k$, $D\chi_k^2 = 2k$.
        * Устойчивость по суммированию: если $\varphi \sim H_k$ и $\psi \sim H_m$ независимы, то $\varphi + \psi \sim H_{k+m}$.

* **Распределение Стьюдента с k степенями свободы ($T_k$):**
    * Определение: распределение случайной величины: $t_k = \frac{\xi_0}{\sqrt{\chi_k^2 / k}}$, где $\xi_0 \sim N(0,1)$ и $\chi_k^2 \sim H_k$ независимы.
    * Свойства:
        * Симметричность: если $t_k \sim T_k$, то $-t_k \sim T_k$.
        * Сходимость к нормальному распределению: $t_k \Rightarrow N(0,1)$ при $k \to \infty$.

* **Лемма Фишера:** Если $X_1,...,X_n$ - выборка из $N(a, \sigma^2)$, то:
    * $\sqrt{n} \frac{\overline{X} - a}{\sigma} \sim N(0,1)$.
    * $\frac{(n-1)S_0^2}{\sigma^2} \sim H_{n-1}$.
    * $\overline{X}$ и $S_0^2$ независимы.

## 11. Построение доверительного интервала для мат. ожидания нормально распределенной генеральной совокупности, при известной дисперсии.** _(Лекция 6, п. 6.6)_

Используя пункт 1 Следствия 5 из Лекции 6,  $\sqrt{n} \frac{\overline{X} - a}{\sigma} \sim N(0,1)$,  и квантили стандартного нормального распределения $\tau_{1-\epsilon/2}$, получаем  точный доверительный интервал для параметра  $a$:

$$P_{a, \sigma^2} \left( \overline{X} - \frac{\tau_{1-\epsilon/2} \sigma}{\sqrt{n}} < a < \overline{X} + \frac{\tau_{1-\epsilon/2} \sigma}{\sqrt{n}} \right) = 1 - \epsilon$$

## 12. Построение доверительного интервала для мат. ожидания нормально распределенной генеральной совокупности, при неизвестной дисперсии.** _(Лекция 6, п. 6.6)_

Используя пункт 4 Следствия 5 из Лекции 6, $\sqrt{n} \frac{\overline{X} - a}{S_0} \sim T_{n-1}$,  и квантили распределения Стьюдента $t_{n-1, 1-\epsilon/2}$, получаем  точный доверительный интервал для параметра  $a$:

$$P_{a, \sigma^2} \left( \overline{X} - \frac{t_{n-1, 1-\epsilon/2} S_0}{\sqrt{n}} < a < \overline{X} + \frac{t_{n-1, 1-\epsilon/2} S_0}{\sqrt{n}} \right) = 1 - \epsilon$$

## 13. Построение доверительного интервала для дисперсии нормально распределенной генеральной совокупности, при известном мат. ожидании.** _(Лекция 6, п. 6.6)_

Используя пункт 2 Следствия 5 из Лекции 6, $\frac{n \sigma_*^2}{\sigma^2} \sim H_n$, где $\sigma_*^2 = \frac{1}{n} \sum_{i=1}^{n} (X_i - a)^2$, и квантили распределения $\chi^2$: $g_1 = \chi_{n, \epsilon/2}^2$ и $g_2 = \chi_{n, 1-\epsilon/2}^2$, получаем точный доверительный интервал для параметра $\sigma^2$:

$$P_{a, \sigma^2} \left( \frac{n \sigma_*^2}{g_2} < \sigma^2 < \frac{n \sigma_*^2}{g_1} \right) = 1 - \epsilon$$

## 14. Построение доверительного интервала для дисперсии нормально распределенной генеральной совокупности, при неизвестном мат. ожидании.** _(Лекция 6, п. 6.6)_

Используя пункт 3 Следствия 5 из Лекции 6, $\frac{(n-1)S_0^2}{\sigma^2} \sim H_{n-1}$, где $S_0^2 = \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \overline{X})^2$,  и квантили распределения $\chi^2$: $g_1 = \chi_{n-1, \epsilon/2}^2$ и $g_2 = \chi_{n-1, 1-\epsilon/2}^2$, получаем точный доверительный интервал для параметра $\sigma^2$:

$$P_{a, \sigma^2} \left( \frac{(n-1)S_0^2}{g_2} < \sigma^2 < \frac{(n-1)S_0^2}{g_1} \right) = 1 - \epsilon$$


## 15. Статистическая проверка гипотез. Критерии. Ошибки i-ого рода.** _(Лекция 7, п. 7.1)_

* **Статистическая проверка гипотез** - это процедура принятия решения о том, согласуются ли данные с выдвинутой гипотезой.
* **Гипотеза** - это предположение о распределении случайной величины.
* **Критерий** - это правило, по которому принимается решение о принятии или отклонении гипотезы.
* **Ошибка i-ого рода** - это ошибка, которая происходит, когда верная гипотеза $H_i$ отклоняется. 

## 16. Способы сравнения критериев. Наиболее мощные критерии. Лемма Неймана-Пирсона.** _(Лекция 7, п. 7.3, 7.4, 7.5)_

* **Способы сравнения критериев:**
    * **Минимаксный подход:** Критерий, минимизирующий максимальную из вероятностей ошибок 1-го и 2-го рода.
    * **Байесовский подход:** Критерий, минимизирующий средневзвешенную вероятность ошибки (или математическое ожидание потерь).
    * **Выбор наиболее мощного критерия:** Критерий, максимизирующий мощность (вероятность принятия верной гипотезы) при фиксированном уровне (вероятность ошибки 1-го рода).
* **Наиболее мощный критерий (НМК)** уровня $\epsilon$ - это критерий, который имеет максимальную мощность среди всех критериев с уровнем не больше $\epsilon$.
* **Лемма Неймана-Пирсона:** Критерий отношения правдоподобия является НМК для проверки двух простых гипотез (Лекция 7, Лемма 11).

## 17. Проверка гипотез о законах распределения. Общие принципы построения критериев согласия.** _(Лекция 8, п. 8.2)_

* **Критерии согласия** - это критерии, которые используются для проверки гипотез о законе распределения случайной величины.
* **Общие принципы построения:**
    1. Задается функция отклонения $\rho(\overline{X})$, которая:
        * Сходится к известному распределению при выполнении проверяемой гипотезы.
        * Неограниченно возрастает при невыполнении гипотезы.
    2. Выбирается пороговое значение $C$ на основе заданного уровня значимости $\epsilon$.
    3. Гипотеза принимается, если $\rho(\overline{X}) < C$, и отклоняется, если $\rho(\overline{X}) > C$.

## 18. Критерий согласия Колмогорова.** _(Лекция 8, п. 8.3)_

* **Суть критерия:** используется для проверки гипотезы о том, что выборка взята из распределения с заданной непрерывной функцией распределения. 
* **Функция отклонения:**  $\rho(\overline{X}) = \sqrt{n} \sup_y |F_n^*(y) - F_1(y)|$, где $F_n^*(y)$ - эмпирическая функция распределения, построенная по выборке, а $F_1(y)$ -  теоретическая функция распределения, соответствующая проверяемой гипотезе $H_1: F = F_1$.
* **Распределение при выполнении гипотезы:**  при $n \to \infty$ функция отклонения $\rho(\overline{X})$ сходится по распределению к случайной величине с распределением Колмогорова (Теорема 3). 
* **Критическая область:** определяется квантилем уровня $1 - \epsilon$ распределения Колмогорова. 


## 19. Критерий согласия $\chi^2$-Пирсона.** _(Лекция 8, п. 8.4)_

* **Суть критерия:** используется для проверки гипотезы о том, что выборка взята из распределения с заданными вероятностями попадания в интервалы группировки.
* **Функция отклонения:** 
$$\rho(\overline{X}) = \sum_{j=1}^{k} \frac{(\nu_j - np_j)^2}{np_j}$$, 
где $\nu_j$ - число элементов выборки, попавших в $j$-й интервал, $p_j$ - теоретическая вероятность попадания в этот интервал, $k$ - число интервалов группировки.
* **Распределение при выполнении гипотезы:** при $n \to \infty$ функция отклонения  $\rho(\overline{X})$ сходится по распределению к $\chi^2$-распределению с $k-1$ степенью свободы (Теорема 12).
* **Критическая область:** определяется квантилем уровня $1 - \epsilon$  $\chi^2$-распределения с $k-1$ степенью свободы. 
* **Замечания:**
    * Критерий применим для проверки как простых, так и сложных гипотез о распределении. 
    * Важно правильно выбрать число интервалов группировки, чтобы обеспечить достаточную точность аппроксимации распределения статистики критерия $\chi^2$-распределением.

## 20. Критерий согласия $\chi^2$-Пирсона (параметрическая гипотеза).** _(Лекция 8, п. 8.5)_

* **Суть критерия:** используется для проверки гипотезы о том, что выборка взята из параметрического семейства распределений. 
* **Функция отклонения:**  та же, что и в  критерии $\chi^2$-Пирсона, но теоретические вероятности $p_j$ заменяются на их оценки $\hat{p}_j$, полученные по выборке,  например,  с помощью метода максимального правдоподобия. 
* **Распределение при выполнении гипотезы:** при  $n \to \infty$  функция отклонения сходится по распределению к  $\chi^2$-распределению с $k-m-1$  степенями свободы, где  $m$ - размерность вектора параметров (Теорема 13). 
* **Замечания:**
    * Аналогичны замечаниям к критерию согласия $\chi^2$-Пирсона. 

## 21. Проверка гипотезы однородности: критерий Колмогорова – Смирнова.** _(Лекция 8, п. 8.6)_

* **Суть критерия:**  используется для проверки гипотезы о том, что две выборки взяты из одного и того же распределения с непрерывной функцией распределения. 
* **Функция отклонения:** 
$$\rho(\overline{X}, \overline{Y}) = \sqrt{\frac{mn}{m+n}} \sup_t |F_{n,x}^*(t) - F_{m,y}^*(t)|,$$
где  $F_{n,x}^*(t)$  и  $F_{m,y}^*(t)$ - эмпирические функции распределения, построенные по выборкам  $\overline{X}$  и  $\overline{Y}$  соответственно,  $n$  и  $m$ - объемы выборок.
* **Распределение при выполнении гипотезы:**  при $n, m \to \infty$ функция отклонения сходится по распределению к случайной величине с распределением Колмогорова (Теорема 14).

## 22. Проверка гипотезы независимости: критерий $\chi^2$-Пирсона.** _(Лекция 8, п. 8.7)_

* **Суть критерия:** используется для проверки гипотезы о независимости двух случайных величин, наблюдаемых совместно. 
* **Функция отклонения:**  
$$\rho(\overline{X}, \overline{Y}) = n \sum_{i=1}^{k} \sum_{j=1}^{m} \frac{(\nu_{i,j} - (\nu_{i, \cdot} \nu_{\cdot, j})/n)^2}{\nu_{i, \cdot} \nu_{\cdot, j}},$$
где $\nu_{i,j}$ - число пар $(X_l, Y_l)$, попавших в область $\Delta_i^x \times \Delta_j^y$, $\nu_{i, \cdot}$ - число пар $(X_l, Y_l)$ таких, что $X_l \in \Delta_i^x$, $\nu_{\cdot, j}$ - число пар $(X_l, Y_l)$ таких, что $Y_l \in \Delta_j^y$, $k$ - число интервалов группировки для значений $X$, $m$ - число интервалов группировки для значений $Y$.
* **Распределение при выполнении гипотезы:** при $n \to \infty$ функция отклонения сходится по распределению к $\chi^2$-распределению с $(k-1)(m-1)$ степенями свободы (Теорема 15).

## 23. Проверка гипотез о параметрах нормального распределения.** _(Лекция 8, п. 8.8, 8.9, 8.10)_

* **Суть:** проверка гипотез о значениях параметров $a$ (математическое ожидание) и $\sigma^2$ (дисперсия) нормального распределения. 
* **Критерии:**
    * **Критерий Стьюдента:** используется для проверки гипотезы о равенстве средних двух нормальных совокупностей с равными, но неизвестными дисперсиями (Теорема 16).
    * **Критерий, основанный на нормальном распределении:**  используется для проверки гипотезы о среднем нормальной совокупности при известной дисперсии. 
    * **Критерий, основанный на распределении Стьюдента:** используется для проверки гипотезы о среднем нормальной совокупности при неизвестной дисперсии. 

## 24. Критерии, основанные на доверительных интервалах.** _(Лекция 8, п. 8.11)_

* **Суть:** гипотеза о значении параметра отклоняется, если это значение не попадает в доверительный интервал для этого параметра.
* **Уровень значимости:** равен уровню значимости, использованному при построении доверительного интервала.

## 25. Непараметрические критерии. Критерий знаков. Критерий Вилкоксона.** _(Не рассматривались в лекциях)_

* **Непараметрические критерии** - это критерии, которые не требуют знания закона распределения генеральной совокупности.
* **Критерий знаков** - используется для проверки гипотезы о медиане распределения.
* **Критерий Вилкоксона** - используется для сравнения двух выборок. 

## 26. Понятие о регрессии. Общая модель линейной регрессии. Ошибка прогноза.** _(Лекция 9, п. 9.1, 9.3)_

* **Регрессия** - это статистическая зависимость  среднего значения одной случайной величины от значений другой (или других) случайной величины. 
* **Общая модель линейной регрессии:**  
$E X = \beta_1 Z_1 + ... + \beta_k Z_k$, 
где $X$ - наблюдаемая случайная величина, $Z_1,...,Z_k$ - факторы регрессии (случайные величины или известные константы), $\beta_1,...,\beta_k$ -  параметры регрессии. 
* **Ошибка прогноза:**  разница между наблюдаемым значением  $X$  и его прогнозом, полученным по модели регрессии. 
